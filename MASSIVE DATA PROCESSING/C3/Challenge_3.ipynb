{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRPUMO2Qym7d"
   },
   "source": [
    "# CHALLENGE 3: FINE TUNING OF LLM MODELS\n",
    "\n",
    "- Enrique Álmazan\n",
    "- Victor Miguel Álvarez Camarero\n",
    "- Javier Alfonso Villolo Fernández.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kfSpINaizU42",
    "outputId": "cbfa09fd-3111-4076-f14c-4f75b719a141"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: pin: command not found\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.30.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.43.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.2.1+cu121)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.25.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.11.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.2.1+cu121)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.40.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.4)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.30.0)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2023.6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.11.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.23.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.0)\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: trl in /usr/local/lib/python3.10/dist-packages (0.8.6)\n",
      "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl) (2.2.1+cu121)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from trl) (4.40.1)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from trl) (1.25.2)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from trl) (0.30.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from trl) (2.19.1)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl) (0.8.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (4.11.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl) (12.4.127)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.23.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (4.66.4)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->trl) (5.9.5)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (2.0.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.9.5)\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.25.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.4)\n"
     ]
    }
   ],
   "source": [
    "!pin install datasets\n",
    "!pip install accelerate\n",
    "!pip install bitsandbytes\n",
    "!pip install peft\n",
    "!pip install evaluate\n",
    "!pip install trl\n",
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EB4KJzGuyjtG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, pipeline\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "from huggingface_hub import notebook_login\n",
    "import evaluate\n",
    "from trl import SFTTrainer\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVrux-ARiSiD"
   },
   "source": [
    "## **Basic concepts before starting:**\n",
    "\n",
    "**- LoRA:** is a fine-tuning technique for large language models. It involves training additional \"relevance parameters\" alongside the main model parameters. These relevance parameters determine the importance or relevance of each layer's contribution to the final prediction. By adjusting these parameters, the model learns which layers are more relevant for the task at hand, enabling it to focus more on important parts of the input data. LoRA fine-tuning optimizes the entire model, including both the main parameters and the relevance parameters. In other words, it trains weights over each of the existing layer to train the model for an specific task indentifying more relevant layers for that task\n",
    "\n",
    "**- Transfer Learning:** Transfer learning is about taking the model that had learned on general-purpose, massive datasets and training it on distinct, task-specific data. This dataset may include labeled examples related to that domain. Transfer learning is used when there is not enough data or a lack of time to train data. It involves transferring knowledge from one task or domain to another. It means using a pre-trained model trained on a large dataset for a general task (such as language modeling) and fine-tuning it on a specific task or dataset of interest. Transfer learning can be achieved through various methods, including feature extraction (using the pre-trained model as a fixed feature extractor) and fine-tuning (updating the parameters of the pre-trained model on the target task), LoRA being one of them.\n",
    "\n",
    "**- Prompt tuning:** Prompt tuning involves explicitly providing the model with task-specific prompts during fine-tuning. Instead of relying solely on the input data to learn the task, the model is guided by these prompts to produce task-specific outputs. LoRA introduces additional parameters. Whereas Prompt tuning teaches a specific task through prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XR5uyKola7__"
   },
   "outputs": [],
   "source": [
    "# Clean the cache before traning each model to avoid memory errors\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Id7MvESxypzH",
    "outputId": "f9c55c98-0e9b-42b2-9fc4-ef43b351f7d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available CUDA devices: 1\n",
      "GPU index 0 : Tesla T4\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA (GPU) is available\n",
    "# For processing with GPU instead of CPU\n",
    "if torch.cuda.is_available():\n",
    "    # Get the number of available CUDA devices\n",
    "    num_devices = torch.cuda.device_count()\n",
    "    print(\"Number of available CUDA devices:\", num_devices)\n",
    "\n",
    "    # Iterate over CUDA devices and print their indices and names\n",
    "    for i in range(num_devices):\n",
    "        print(\"GPU index\", i, \":\", torch.cuda.get_device_name(i))\n",
    "else:\n",
    "    print(\"CUDA is not available. CPU will be used.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "9bc6f0a4987940e98b7fe5e94d2c427e",
      "cac50e0e9b2c4046be586067164f0f59",
      "0422f8362a1a4d56a79ecceba8162e73",
      "d48ebe64e8bb4badb0cc9bc64fb492de",
      "64f365d454be4b55b59c7c1f0b960d17",
      "fa4745d48e53457b981a8b232805d211",
      "a11250a257d342229e90862f4fdf9fca",
      "501ef8141c6143338a01b86210e057e1",
      "5a229a741ad74f1082806e63be3f8a40",
      "cbd26274a21d40e8b6ef028369e70bcb",
      "53d00ebb4cd14452bdc4d2bfa2cb7c88",
      "dbb5068ea6cd4497a0bd2a1a96d4acbc",
      "6797160bcd644bce88dadfc596d153a6",
      "812ee2c261764677ae7f1cc278285bab"
     ]
    },
    "id": "ybkBuXgQ2geA",
    "outputId": "ba393b1d-195c-478e-cfc3-fd33a0ab3a63"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc6f0a4987940e98b7fe5e94d2c427e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4acfmegNHQz3"
   },
   "outputs": [],
   "source": [
    "# Your token has been saved to /root/.cache/huggingface/token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fbLsV0IT0r8j"
   },
   "outputs": [],
   "source": [
    "# Base model\n",
    "# Llama-2-7b-hf model architecture: It is an auto-regressive language model that uses an optimized transformer architecture.\n",
    "# It is possible to the official Meta Llama-2 model from Hugging Face, but you have to apply and wait a couple of days for confirmation.\n",
    "# Model: https://huggingface.co/meta-llama/Llama-2-7b-hf\n",
    "# Paper: https://arxiv.org/abs/2307.09288\n",
    "# More info: https://llama.meta.com/llama2/\n",
    "\n",
    "#model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-hf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVvofBRLedes"
   },
   "source": [
    "## **Objective**\n",
    "\n",
    "Compare the performance of **Llama-2-7b-hf** model seen in class with another model from the Hugging Face provider in terms of rouge coefficients and the time of execution. For our second model we have chosen **Mistral-7B-Instruct-v0.2**. We opt for Mistral's Mistral-7B-Instruct-v0.2 model as it has a parameter count similar to that of the Llama model. Our aim is to assess the variance across the two model architectures which have been trained with different data and gauge their efficacy when fine tuned independently, irrespective of parameter count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHHOgDd8Ggde"
   },
   "outputs": [],
   "source": [
    "# Base model\n",
    "# Model: https://huggingface.co/meta-llama/Meta-Llama-3-8B\n",
    "\n",
    "# New model:\n",
    "# Model: https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I3CZzF-HMAnD",
    "outputId": "54b783aa-86e2-4a42-d87e-46ee5fd95aa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training OK\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "# Train\n",
    "url_train = \"https://raw.githubusercontent.com/architkaila/Fine-Tuning-LLMs-for-Medical-Entity-Extraction/main/data/entity_extraction/entity-extraction-train-data.json\"\n",
    "response_train = requests.get(url_train)\n",
    "if response_train.status_code == 200:\n",
    "    data_train = response_train.json()\n",
    "    print(\"Training OK\")\n",
    "else:\n",
    "    print(\"Error obtaining training data:\", response_train.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "75YTxsbyX4o3",
    "outputId": "3d37f021-9a5b-42bd-e7ff-4c317f69cdb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"Robert Johnson\\nrobert.johnson@email.com\\n789 Maple Lane, Chicago, IL 60601\\n555-234-5678, United States\\n\\nRelationship to XYZ Pharma Inc.: Patient\\nReason for contacting: Adverse Event\\n\\nMessage: I've been on Onglyza for a while, and I've noticed that I'm experiencing frequent painful urination. Is this a known side effect?\",\n",
       " 'output': '{\"drug_name\": \"Onglyza\", \"adverse_events\": [\"painful urination\"]}'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FiG1q5wfOTh1",
    "outputId": "922cecdd-d4b8-4359-d89d-a0c095230b82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test OK\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "url_test = \"https://raw.githubusercontent.com/architkaila/Fine-Tuning-LLMs-for-Medical-Entity-Extraction/main/data/entity_extraction/entity-extraction-test-data.json\"\n",
    "response_test = requests.get(url_test)\n",
    "if response_test.status_code == 200:\n",
    "    data_test = response_test.json()\n",
    "    print(\"Test OK\")\n",
    "else:\n",
    "    print(\"Error obtaining test data:\", response_test.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H0sqvOpzm7RG",
    "outputId": "1c0d7de6-8bf6-436b-dbb9-e01ce448be71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"Natalie Cooper,\\nncooper@example.com\\n6789 Birch Street, Denver, CO 80203,\\n303-555-6543, United States\\n\\nRelationship to XYZ Pharma Inc.: Patient\\nReason for contacting: Adverse Event\\n\\nMessage: Hi, after starting Abilify for bipolar I disorder, I've noticed that I am experiencing nausea and vomiting. Are these typical reactions? Best, Natalie Cooper\",\n",
       " 'output': '{\"drug_name\": \"Abilify\", \"adverse_events\": [\"nausea\", \"vomiting\"]}'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0TLmL59B1c_"
   },
   "source": [
    "```\n",
    "---- LlaMa2 datasets ----\n",
    "https://gpus.llm-utils.org/llama-2-prompt-template/\n",
    "Note that this only applies to the llama 2 chat models. The base models have no prompt structure, they’re raw non-instruct tuned models.\n",
    "\n",
    "<s>[INST] {user_message_1} [/INST] {model_reply_1}</s>\n",
    "\n",
    "---- Alpaca datasets ----\n",
    "### Instruction:\n",
    "(Instruction Text)\n",
    "\n",
    "### Input:\n",
    "(Auxiliary Input Text)\n",
    "\n",
    "### Response:\n",
    "(Desired Response Text)\n",
    "\n",
    "---- Vicuna datasets ----\n",
    "Vicuna datasets\n",
    "### Human:\n",
    "(Question Text)\n",
    "### Assistant:\n",
    "(Response Text)\n",
    "\n",
    "---- Mistral datasets ----\n",
    "<s>[INST] Instruction [/INST] Model answer</s>\n",
    "\n",
    "---- Gemma ----\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDpjnAxSfE0G"
   },
   "source": [
    "## **Pre-Processing**\n",
    "\n",
    "Now we format the data from the dataset downloaded to fit the prompt structure\n",
    "of the LLM model. Fortunatelly we can preserve the arrangement seen in class as Llama and Mistral have the same structure.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0S2AT2PgOh29"
   },
   "outputs": [],
   "source": [
    "# Without a system message\n",
    "# <s>[INST] {user_message_1} [/INST] {model_reply_1}</s>\n",
    "\n",
    "formatted_data_train = []\n",
    "\n",
    "for item in data_train:\n",
    "    input_text = item[\"input\"]\n",
    "    output_text = item[\"output\"]\n",
    "\n",
    "    formatted_input = f\"<s>[INST] {input_text}[/INST]\"\n",
    "\n",
    "    formatted_output = output_text.replace('\\\"', '').replace('{', '').replace('}', '')\n",
    "\n",
    "    formatted_data_train.append({'text':formatted_input + formatted_output + '</s>'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yacvt_tenB61",
    "outputId": "a14552cd-4aad-4e80-a089-15c493de7f09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"<s>[INST] Robert Johnson\\nrobert.johnson@email.com\\n789 Maple Lane, Chicago, IL 60601\\n555-234-5678, United States\\n\\nRelationship to XYZ Pharma Inc.: Patient\\nReason for contacting: Adverse Event\\n\\nMessage: I've been on Onglyza for a while, and I've noticed that I'm experiencing frequent painful urination. Is this a known side effect?[/INST]drug_name: Onglyza, adverse_events: [painful urination]</s>\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_data_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-rYO-eSuznD"
   },
   "outputs": [],
   "source": [
    "dataset_train = Dataset.from_list(formatted_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RvHxaqW9u2uU",
    "outputId": "4faf5cb4-8fd8-4448-da86-a94f2ef345db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 700\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nskmwnkxu4Km",
    "outputId": "53fcc3fc-cb43-467f-980a-ab79e9b3286d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"<s>[INST] Robert Johnson\\nrobert.johnson@email.com\\n789 Maple Lane, Chicago, IL 60601\\n555-234-5678, United States\\n\\nRelationship to XYZ Pharma Inc.: Patient\\nReason for contacting: Adverse Event\\n\\nMessage: I've been on Onglyza for a while, and I've noticed that I'm experiencing frequent painful urination. Is this a known side effect?[/INST]drug_name: Onglyza, adverse_events: [painful urination]</s>\"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zIThhRE-nHVV"
   },
   "outputs": [],
   "source": [
    "formatted_data_test = []\n",
    "\n",
    "for item in data_test:\n",
    "    input_text = item[\"input\"]\n",
    "    output_text = item[\"output\"]\n",
    "\n",
    "    formatted_input = f\"<s>[INST] {input_text}[/INST]\"\n",
    "\n",
    "    formatted_output = output_text.replace('\\\"', '').replace('{', '').replace('}', '')\n",
    "\n",
    "    formatted_data_test.append({'text':formatted_input + formatted_output + '</s>'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m9t231_pnNyo",
    "outputId": "89cff839-47be-4ffb-8380-9127fb3cb322"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"<s>[INST] Natalie Cooper,\\nncooper@example.com\\n6789 Birch Street, Denver, CO 80203,\\n303-555-6543, United States\\n\\nRelationship to XYZ Pharma Inc.: Patient\\nReason for contacting: Adverse Event\\n\\nMessage: Hi, after starting Abilify for bipolar I disorder, I've noticed that I am experiencing nausea and vomiting. Are these typical reactions? Best, Natalie Cooper[/INST]drug_name: Abilify, adverse_events: [nausea, vomiting]</s>\"}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_data_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqJiF0YVunCo"
   },
   "outputs": [],
   "source": [
    "dataset_test = Dataset.from_list(formatted_data_test) # HuggingFace Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRc6NdrBuqeD",
    "outputId": "f550a957-75f0-4574-e061-c60c0d7f10b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 59\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F3kiGUdkuvDY",
    "outputId": "4bc65d7a-2036-4ec5-848b-9f4ba40c8b31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"<s>[INST] Natalie Cooper,\\nncooper@example.com\\n6789 Birch Street, Denver, CO 80203,\\n303-555-6543, United States\\n\\nRelationship to XYZ Pharma Inc.: Patient\\nReason for contacting: Adverse Event\\n\\nMessage: Hi, after starting Abilify for bipolar I disorder, I've noticed that I am experiencing nausea and vomiting. Are these typical reactions? Best, Natalie Cooper[/INST]drug_name: Abilify, adverse_events: [nausea, vomiting]</s>\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VcHB8b8Rmzq8",
    "outputId": "0353c009-edf2-4035-cfe7-9421823f26e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\") # Load tokenizer, specify the one for the corresponding LLM model\n",
    "tokenizer.pad_token = tokenizer.eos_token # Padding token of the tokenizer to be the same as the end-of-sequence (eos) token\n",
    "tokenizer.padding_side = \"right\" # Padding should be added to the right side of the input sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "5e2f2607b4ab4df581c62c618a34cad6",
      "1de1accd159e42f68e57fd67e525cb2b",
      "644bffbb621244faa331f8cde91c8f78",
      "5901cc21e51d477d937541d264af3fda",
      "4014402ce60647afa00365d41ac12264",
      "8f1e5ea19a4d4e6893ddbd3e9fbad481",
      "ae6cf00577974250a29b6293a973b53f",
      "799d600da6fe49e48e3909cca4843386",
      "1b7a1f23f4ed44bda9066b869bdaddf1",
      "a664acb85354486abad3bb14ab1c41ad",
      "188b268e9f0b47598c9a39490183b255"
     ]
    },
    "id": "WtqkQwzy2Cpd",
    "outputId": "9fd59e71-8711-4ff8-983c-01e54d7822f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['Load_in_4bit']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e2f2607b4ab4df581c62c618a34cad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Base model\n",
    "# We will use NousResearch's Llama-2-7b-chat-hf as a base model, which is the same as the original, but easily accessible.\n",
    "# Model: https://huggingface.co/NousResearch/Llama-2-7b-chat-hf\n",
    "\n",
    "# New model\n",
    "# We will use Mistral's Mistral-7B-Instruct-v0.2. Our aim is to assess the variance across various model architectures and gauge their efficacy when trained independently, irrespective of parameter count.\n",
    "\n",
    "# Create quantization config (reduce precision as well as size)\n",
    "# https://huggingface.co/docs/transformers/main_classes/quantization\n",
    "# Quantization techniques reduce memory and computational costs\n",
    "# by representing weights and activations with lower-precision data types\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    Load_in_4bit=True, # This flag is used to enable 4-bit quantization\n",
    "    bnb_4bit_compute_dtype=torch.float16, # This sets the computational type: once the weights are loaded in 4-bit, the computations will be performed using 16-bit floating-point precision.\n",
    "    bnb_4bit_quant_type=\"nf4\" # This sets the quantization data type\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", # Load model\n",
    "                                             quantization_config= quantization_config, # Quantification configuration\n",
    "                                             device_map=0 # device_map = 0 means put the whole model on GPU 0; device_map=\"auto\" compute the most optimized `device_map` automatically\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6lXsRT1iWbEc",
    "outputId": "8e853028-e80e-4dea-ca7e-5b66d1d6f991"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MistralForCausalLM(\n",
      "  (model): MistralModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x MistralDecoderLayer(\n",
      "        (self_attn): MistralSdpaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): MistralRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): MistralMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): MistralRMSNorm()\n",
      "        (post_attention_layernorm): MistralRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): MistralRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7chiONHWW9Fi"
   },
   "source": [
    "### Zero-shot\n",
    "\n",
    "Here we are Introducing formatted input without the solution for the model to suse previous learning to come up with an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "phHJPYzwjuMj",
    "outputId": "a8455c63-435e-4191-d8a5-a3cd8509be69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mia Garcia\n",
      "mia.garcia@email.com\n",
      "321 Magnolia Drive, Dallas, TX 75201\n",
      "555-890-1234, United States\n",
      "\n",
      "Relationship to XYZ Pharma Inc.: Patient\n",
      "Reason for contacting: Adverse Event\n",
      "\n",
      "Message: I experienced a feeling of light-headedness and near-fainting after taking Staxyn for my erectile dysfunction. Is this a common side effect, and should I be worried?\n"
     ]
    }
   ],
   "source": [
    "print(data_test[1]['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qv_oGX-Bc0aI",
    "outputId": "a818376b-d1ab-43f6-ec1b-e94bf8b73ee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Mia Garcia\n",
      "mia.garcia@email.com\n",
      "321 Magnolia Drive, Dallas, TX 75201\n",
      "555-890-1234, United States\n",
      "\n",
      "Relationship to XYZ Pharma Inc.: Patient\n",
      "Reason for contacting: Adverse Event\n",
      "\n",
      "Message: I experienced a feeling of light-headedness and near-fainting after taking Staxyn for my erectile dysfunction. Is this a common side effect, and should I be worried? [/INST] Subject: Report of Adverse Event - Staxyn and Light-headedness\n",
      "\n",
      "Dear XYZ Pharma Inc. Team,\n",
      "\n",
      "I hope this message finds you well. I am writing to report an adverse event I recently experienced after taking Staxyn, a medication I have been using to manage my erectile dysfunction.\n",
      "\n",
      "On\n"
     ]
    }
   ],
   "source": [
    "# Run text generation pipeline with our model\n",
    "prompt = data_test[1]['input']\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ys1RLzyWXXVZ",
    "outputId": "41d0dbe3-31ee-4cfe-f530-e806a11bfedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brandon Lee,\n",
      "blee@example.com\n",
      "3333 Pine Road, Hilltown, MA 02108,\n",
      "617-555-3333, United States\n",
      "\n",
      "Relationship to XYZ Pharma Inc.: Patient\n",
      "Reason for contacting: Adverse Event\n",
      "\n",
      "Message: Since I started on Byetta, I've noticed an increase in thirst and dry mouth. Is this related to the medication? Best, Brandon Lee\n"
     ]
    }
   ],
   "source": [
    "print(data_test[2]['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_9VbIoojXU3B",
    "outputId": "0fad589a-8f2b-4776-bb9b-0c5adb86ccf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Brandon Lee,\n",
      "blee@example.com\n",
      "3333 Pine Road, Hilltown, MA 02108,\n",
      "617-555-3333, United States\n",
      "\n",
      "Relationship to XYZ Pharma Inc.: Patient\n",
      "Reason for contacting: Adverse Event\n",
      "\n",
      "Message: Since I started on Byetta, I've noticed an increase in thirst and dry mouth. Is this related to the medication? Best, Brandon Lee [/INST] Subject: Report of Potential Adverse Effect from Byetta\n",
      "\n",
      "Dear Brandon Lee,\n",
      "\n",
      "Thank you for reaching out to XYZ Pharma Inc. regarding your experience with Byetta. We take all reports of adverse events seriously and appreciate your feedback.\n",
      "\n",
      "Your symptoms of increased thirst and dry mouth are known side effects of Byetta. These symptoms are typically related to the medication'\n"
     ]
    }
   ],
   "source": [
    "# Run text generation pipeline with our model\n",
    "prompt = data_test[2]['input']\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aip6WC06Xudi"
   },
   "source": [
    "### One-shot\n",
    "\n",
    "In this case we introduce formatted input with its respective formatted output and then another formatted input without the solution for the model to use previous example to guide answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7eAo-9bIX2yq",
    "outputId": "e4f0feb3-9a65-4154-f6aa-df43a7df9a0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Natalie Cooper,\n",
      "ncooper@example.com\n",
      "6789 Birch Street, Denver, CO 80203,\n",
      "303-555-6543, United States\n",
      "\n",
      "Relationship to XYZ Pharma Inc.: Patient\n",
      "Reason for contacting: Adverse Event\n",
      "\n",
      "Message: Hi, after starting Abilify for bipolar I disorder, I've noticed that I am experiencing nausea and vomiting. Are these typical reactions? Best, Natalie Cooper[/INST]drug_name: Abilify, adverse_events: [nausea, vomiting]</s>\n",
      "<s>[INST] Mia Garcia\n",
      "mia.garcia@email.com\n",
      "321 Magnolia Drive, Dallas, TX 75201\n",
      "555-890-1234, United States\n",
      "\n",
      "Relationship to XYZ Pharma Inc.: Patient\n",
      "Reason for contacting: Adverse Event\n",
      "\n",
      "Message: I experienced a feeling of light-headedness and near-fainting after taking Staxyn for my erectile dysfunction. Is this a common side effect, and should I be worried? [/INST]\n"
     ]
    }
   ],
   "source": [
    "prompt = dataset_test[0]['text'] + '\\n' + f\"<s>[INST] {data_test[1]['input']} [/INST]\"\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NBSoCg_UMYUl",
    "outputId": "8988f4a0-a238-4015-a61a-cd6919d3ed6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Natalie Cooper,\n",
      "ncooper@example.com\n",
      "6789 Birch Street, Denver, CO 80203,\n",
      "303-555-6543, United States\n",
      "\n",
      "Relationship to XYZ Pharma Inc.: Patient\n",
      "Reason for contacting: Adverse Event\n",
      "\n",
      "Message: Hi, after starting Abilify for bipolar I disorder, I've noticed that I am experiencing nausea and vomiting. Are these typical reactions? Best, Natalie Cooper[/INST]drug_name: Abilify, adverse_events: [nausea, vomiting]</s>\n"
     ]
    }
   ],
   "source": [
    "print(dataset_test[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CcbCQv1AYfI0",
    "outputId": "269e9d4b-d72a-44b8-968f-8e07969be567"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Natalie Cooper,\n",
      "ncooper@example.com\n",
      "6789 Birch Street, Denver, CO 80203,\n",
      "303-555-6543, United States\n",
      "\n",
      "Relationship to XYZ Pharma Inc.: Patient\n",
      "Reason for contacting: Adverse Event\n",
      "\n",
      "Message: Hi, after starting Abilify for bipolar I disorder, I've noticed that I am experiencing nausea and vomiting. Are these typical reactions? Best, Natalie Cooper[/INST]drug_name: Abilify, adverse_events: [nausea, vomiting]</s>\n",
      "<s>[INST] Mia Garcia\n",
      "mia.garcia@email.com\n",
      "321 Magnolia Drive, Dallas, TX 75201\n",
      "555-890-1234, United States\n",
      "\n",
      "Relationship to XYZ Pharma Inc.: Patient\n",
      "Reason for contacting: Adverse Event\n",
      "\n",
      "Message: I experienced a feeling of light-headedness and near-fainting after taking Staxyn for my erectile dysfunction. Is this a common side effect, and should I be worried? [/INST] drug_name: Staxyn, adverse_events: [light-headedness, near-fainting]\n",
      "\n",
      "Response:\n",
      "\n",
      "Subject: Re: Inquiry Regarding Side Effects of Staxyn\n",
      "\n",
      "Dear Mia Garcia,\n",
      "\n",
      "Thank you for reaching out to us regarding your experience with Staxyn. We take all feedback from our patients\n"
     ]
    }
   ],
   "source": [
    "# Run text generation pipeline with our next model\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=350)\n",
    "result = pipe(prompt)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3KBc554dU9h"
   },
   "source": [
    "### Training\n",
    "\n",
    "Now we use the entire dataset with many formatted input and outputs to fine tune the model using the LoRA configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b9Tb0Xnw5uMF"
   },
   "outputs": [],
   "source": [
    "# Create LoRA config\n",
    "# More info in https://huggingface.co/docs/peft/main/en/conceptual_guides/lora\n",
    "peft_config = LoraConfig(\n",
    "    r=8, # The rank of the update matrices, expressed in int. Lower rank results in smaller update matrices with fewer trainable parameters.\n",
    "    target_modules=[\"g_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"], # The modules to apply the LoRA update matrices.\n",
    "    bias=\"none\", # Specifies if the bias parameters should be trained.\n",
    "    task_type = TaskType.CAUSAL_LM\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ZI8dAjpFXb0"
   },
   "outputs": [],
   "source": [
    "# Subset of the arguments thath we use to the training.\n",
    "# https://huggingface.co/docs/transformers/main_classes/trainer\n",
    "\n",
    "training_params = TrainingArguments(\n",
    "    output_dir=\"./results\", # where the model's checkpoints and predictions will be stored\n",
    "    num_train_epochs=1, # number of epochs\n",
    "    per_device_train_batch_size=4, # batch size for training\n",
    "    gradient_accumulation_steps=1, # # Number of update steps to accumulate the gradients for\n",
    "    optim=\"paged_adamw_32bit\", # AdamW optimizer\n",
    "    save_steps=25, # save checkpoint every 25 update steps\n",
    "    logging_steps=25, # logs every 25 update steps\n",
    "    learning_rate=2e-4, # initial learning rate\n",
    "    weight_decay=0.001, # weight decay to apply to all layers except bias/LayerNorm weights\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3, # maximum gradient normal (gradient clipping)\n",
    "    max_steps=-1, # number of training steps (if not -1 overrides num_train_epochs)\n",
    "    warmup_ratio=0.03, # ratio of steps for a linear warmup (from 0 to learning rate)\n",
    "    group_by_length=True, # group sequences into batches with same length\n",
    "    lr_scheduler_type=\"constant\", # learning rate schedule\n",
    "    report_to=\"tensorboard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660,
     "referenced_widgets": [
      "534a133eb01549268934fcaab0929380",
      "b485d8b8d19443b49188e2d5ffdf7fff",
      "18cbebd940ac4b79b4539a3e30d48dac",
      "abc4f72e988d4d2f858ae245d519b671",
      "68577c1cec5f4b00bc99715a3c08df8d",
      "4e29a07d7a144b42ab4cdca49c0b4f6b",
      "cfeb971e25864f0b973deea992ed648e",
      "a28fc4d884d34294bbe8ace07a95561c",
      "8a02d38bfe804a0fb4826cb3e881899b",
      "dbff068036124522a42e87cca208a142",
      "02706a9956cd4a11add8515d709e41ed"
     ]
    },
    "id": "sxyXq6Fnn6fr",
    "outputId": "9ea1cab1-3a7f-4478-c9e9-ebc9a2b329f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:246: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534a133eb01549268934fcaab0929380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='175' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/175 16:24, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.060800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.631900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.488000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.481300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.456500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.482700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.434200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=175, training_loss=0.5764838518415178, metrics={'train_runtime': 991.6445, 'train_samples_per_second': 0.706, 'train_steps_per_second': 0.176, 'total_flos': 4345650882772992.0, 'train_loss': 0.5764838518415178, 'epoch': 1.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set supervised fine-tuning parameters\n",
    "max_seq_length = None\n",
    "packing = False\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset_train,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_params,\n",
    "    packing=packing,\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dsS0kXVAKyoP",
    "outputId": "8bb5e2e1-e70d-4db4-c94a-08902c84d2d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Mia Garcia\n",
      "mia.garcia@email.com\n",
      "321 Magnolia Drive, Dallas, TX 75201\n",
      "555-890-1234, United States\n",
      "\n",
      "Relationship to XYZ Pharma Inc.: Patient\n",
      "Reason for contacting: Adverse Event\n",
      "\n",
      "Message: I experienced a feeling of light-headedness and near-fainting after taking Staxyn for my erectile dysfunction. Is this a common side effect, and should I be worried? [/INST]drug_name: Staxyn, adverse_events: [feeling of light-headedness, near-fainting]\n",
      "\n",
      "Drug information: Staxyn is a medication used to treat erectile dysfunction. It works by increasing blood flow to the penis, allowing a man to get and maintain an erection.\n",
      "\n",
      "Regarding your\n"
     ]
    }
   ],
   "source": [
    "# Run text generation pipeline with our next model\n",
    "prompt = data_test[1]['input']\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dsUR1WPj6Jc1",
    "outputId": "a56c3ff6-0b19-4594-c1ed-6032cd04b8de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Daniel Wilson\n",
      "daniel.wilson@example.com\n",
      "112 Pine Avenue, Atlanta, GA 30301\n",
      "4045554321, United States\n",
      "\n",
      "Relationship to XYZ Pharma Inc.: Patient\n",
      "Reason for contacting: Adverse Event\n",
      "\n",
      "Message: I took Nexium for acid reflux, and I had a headache and stomach pain. Could this be due to the medication? [/INST]drug_name: Nexium, adverse_events: [headache, stomach pain]\n",
      "\n",
      "Drug Information\n",
      "Nexium is a medication used to treat and prevent stomach ulcers, erosive esophagitis, and GERD. It works by blocking the production of stomach acid.\n",
      "\n",
      "Relationship to Adverse Events\n",
      "The adverse events you experienced, headache and stomach pain, are known side effects\n"
     ]
    }
   ],
   "source": [
    "# Run text generation pipeline with our next model\n",
    "prompt = data_test[12]['input']\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8i5psms8eRTr"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "smZzCy6Md8nb"
   },
   "outputs": [],
   "source": [
    "# Evaluate the Model Quantitatively\n",
    "rouge = evaluate.load('rouge') # https://en.wikipedia.org/wiki/ROUGE_(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qJeqkuVIiG2c"
   },
   "outputs": [],
   "source": [
    "input = []\n",
    "\n",
    "for d in data_test:\n",
    "  input.append(f\"<s>[INST] {d['input']} [/INST]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "33_Gn9OVj0jJ"
   },
   "outputs": [],
   "source": [
    "output = dataset_test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "4ox9NLPclJaE"
   },
   "outputs": [],
   "source": [
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=250)\n",
    "\n",
    "output_model = []\n",
    "\n",
    "for i in input:\n",
    "  output_model.append(pipe(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XHGmUD7nnQ5X",
    "outputId": "9891b6f0-e84c-411d-a02f-ca8346034c53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] William Harris\n",
      "william.harris@example.com\n",
      "890 Oak Road, San Francisco, CA 94101\n",
      "4155558765, United States\n",
      "\n",
      "Relationship to XYZ Pharma Inc.: Patient\n",
      "Reason for contacting: Adverse Event\n",
      "\n",
      "Message: I received Neupogen and had trouble breathing and fever. Are these common side effects of the medication?[/INST]drug_name: Neupogen, adverse_events: [trouble breathing, fever]</s>\n"
     ]
    }
   ],
   "source": [
    "print(output[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VomGEA8gkoCK",
    "outputId": "575c6663-b9a5-46d0-be0c-a553538e8ff7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] William Harris\n",
      "william.harris@example.com\n",
      "890 Oak Road, San Francisco, CA 94101\n",
      "4155558765, United States\n",
      "\n",
      "Relationship to XYZ Pharma Inc.: Patient\n",
      "Reason for contacting: Adverse Event\n",
      "\n",
      "Message: I received Neupogen and had trouble breathing and fever. Are these common side effects of the medication? [/INST]drug_name: Neupogen, adverse_events: [trouble breathing, fever]\n",
      "\n",
      "Drug Information\n",
      "Neupogen is a medication used to stimulate the production of white blood cells in the body. It is commonly used during chemotherapy to prevent infections.\n",
      "\n",
      "Adverse Events\n",
      "The adverse events you experienced, trouble breathing and fever, are not common side effects of Neupogen. However, they can be serious and require immediate medical attention.\n",
      "\n",
      "If you have trouble breathing or a fever, contact your healthcare provider right away. These symptoms could be related to an allergic reaction to Neupogen or a side effect of the medication.\n",
      "\n",
      "Additional Information\n",
      "Neupogen can\n"
     ]
    }
   ],
   "source": [
    "output_model__ = []\n",
    "\n",
    "for ii in output_model:\n",
    "  output_model__.append(ii[0]['generated_text'])\n",
    "\n",
    "print(output_model__[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wb_3GfDGmwqv"
   },
   "outputs": [],
   "source": [
    "rouge_results = rouge.compute(\n",
    "    predictions=output_model__,\n",
    "    references=output,\n",
    "    use_aggregator=True, # Scores are averaged over all examples\n",
    "    use_stemmer=True, # Stemmer will be used during the computation of the ROUGE scores (stemmer reduces words to their root form, which can help in matching similar words)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a51feKldnvR_",
    "outputId": "dfa8b3d0-e0be-4aa1-caa8-7e4658e77c93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.6705005718546562, 'rouge2': 0.6584466929107382, 'rougeL': 0.669451575070622, 'rougeLsum': 0.6656510145259794}\n"
     ]
    }
   ],
   "source": [
    "print(rouge_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j1gBdmVVo9UM",
    "outputId": "6f0ccfc2-0d95-4c80-a884-f0392a65d5af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge scores for Llama 2 model: {'rouge1': 0.988583793986618, 'rouge2': 0.9802423646077636, 'rougeL': 0.9873031083402044, 'rougeLsum': 0.9871804787998142}\n",
      "Rouge scores for Mistral 7B 0.2v model: {'rouge1': 0.6705005718546562, 'rouge2': 0.6584466929107382, 'rougeL': 0.669451575070622, 'rougeLsum': 0.6656510145259794}\n"
     ]
    }
   ],
   "source": [
    "# RESULTS FOR LLAMA 2 MODEL\n",
    "#  {'rouge1': 0.988583793986618, 'rouge2': 0.9802423646077636, 'rougeL': 0.9873031083402044, 'rougeLsum': 0.9871804787998142}\n",
    "print(f\"Rouge scores for Llama 2 model: {{'rouge1': 0.988583793986618, 'rouge2': 0.9802423646077636, 'rougeL': 0.9873031083402044, 'rougeLsum': 0.9871804787998142}}\")\n",
    "\n",
    "# RESULTS FOR MISTRAL MODEL\n",
    "# {'rouge1': 0.6705005718546562, 'rouge2': 0.6584466929107382, 'rougeL': 0.669451575070622, 'rougeLsum': 0.6656510145259794}\n",
    "print(f\"Rouge scores for Mistral 7B 0.2v model: {{'rouge1': 0.6705005718546562, 'rouge2': 0c, 'rougeL': 0.669451575070622, 'rougeLsum': 0.6656510145259794}}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZKxpTDdk2xS"
   },
   "source": [
    "#**DISCUSSION**\n",
    "\n",
    "To compare the results lets first provide an explanation of each of the rouge parameters:\n",
    "\n",
    "Overall ROUGE metrics provide a comprehensive evaluation of text generation tasks by considering overlap between generated and reference texts. They help assess the similarity and quality of the generated texts compared to human-written text.\n",
    "\n",
    "**- Rouge 1:** Measures the precision of unigram (single-word) overlap between the generated text and a reference (human-generated) text. It calculates Precision, recall, and F1-score computed based on the number of overlapping unigrams.\n",
    "\n",
    "**- Rouge 2:** Measures the precision of bigram overlap between the generated text and a reference text. Similar to ROUGE-1, but considers pairs of adjacent words (bigrams) instead of single words (unigrams).\n",
    "\n",
    "**- Rouge L:**  Matches the Longest Common Subsequence (LCS) between the generated text and a reference text. Precision, recall, and F1-score are computed based on the longest sequence of words that appear in both the generated and reference texts while preserving the order of the words.\n",
    "\n",
    "**- Rouge Lsum:** considers the sum of the ROUGE-L scores for each reference text. This means that if there are multiple reference texts available for a particular input text, ROUGE-Lsum calculates the ROUGE-L score for each reference-generated pair and then sums up these scores. It considers the performance across all input texts.\n",
    "\n",
    "Once this is clear what we can infer from the obtained results is the following:\n",
    "\n",
    "The difference in precision of unigram overlaps between the Llama 2 model (0.988583793986618) and the Mistral model (0.6705005718546562) indicates that the Llama model has greater precision for unigram overlap.\n",
    "\n",
    "The same occurs with bigram overlap precision with Llama 2 having a rouge2 score of 0.9802423646077636 and Mistral a rouge2 score of 0.6584466929107382.\n",
    "\n",
    "Regarding the matches of longest sequence of words between single reference text and its corresponding generated response as well as the aggreate sum of how well the generated text aligns with multiple reference texts, the precision of rougeL and rougeLsum is significantly lower (0.669451575070622, 0.6656510145259794; respectively) for the Mistral model than for the Llama 2 model (0.9873031083402044, 0.9871804787998142; respectively).\n",
    "\n",
    "It is not only in the scores where we see a noticeable difference in performace. By comparing running times, Llama 2 took 6 minutes for the training of the model and another 5 minutes for generating the text generation pipeline to then evaluate obtained results. Whereas the mistral model took 16 minutes to train and another 15 minutes to generate results.\n",
    "\n",
    "Although both models have a similar parameter size, approximately 7 billion, their performance differs significantly, with the Llama 2 model clearly outperforming the Mistral model. This variance in performance could be attributed to differences in model architecture as well as the quality of the training data utilized for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rngje9e1n30s"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02706a9956cd4a11add8515d709e41ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0422f8362a1a4d56a79ecceba8162e73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a229a741ad74f1082806e63be3f8a40",
      "placeholder": "​",
      "style": "IPY_MODEL_cbd26274a21d40e8b6ef028369e70bcb",
      "value": "Your token has been saved in your configured git credential helpers (store)."
     }
    },
    "188b268e9f0b47598c9a39490183b255": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "18cbebd940ac4b79b4539a3e30d48dac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a28fc4d884d34294bbe8ace07a95561c",
      "max": 700,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8a02d38bfe804a0fb4826cb3e881899b",
      "value": 700
     }
    },
    "1b7a1f23f4ed44bda9066b869bdaddf1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1de1accd159e42f68e57fd67e525cb2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f1e5ea19a4d4e6893ddbd3e9fbad481",
      "placeholder": "​",
      "style": "IPY_MODEL_ae6cf00577974250a29b6293a973b53f",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "4014402ce60647afa00365d41ac12264": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e29a07d7a144b42ab4cdca49c0b4f6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "501ef8141c6143338a01b86210e057e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "534a133eb01549268934fcaab0929380": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b485d8b8d19443b49188e2d5ffdf7fff",
       "IPY_MODEL_18cbebd940ac4b79b4539a3e30d48dac",
       "IPY_MODEL_abc4f72e988d4d2f858ae245d519b671"
      ],
      "layout": "IPY_MODEL_68577c1cec5f4b00bc99715a3c08df8d"
     }
    },
    "53d00ebb4cd14452bdc4d2bfa2cb7c88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5901cc21e51d477d937541d264af3fda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a664acb85354486abad3bb14ab1c41ad",
      "placeholder": "​",
      "style": "IPY_MODEL_188b268e9f0b47598c9a39490183b255",
      "value": " 3/3 [01:03&lt;00:00, 21.15s/it]"
     }
    },
    "5a229a741ad74f1082806e63be3f8a40": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e2f2607b4ab4df581c62c618a34cad6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1de1accd159e42f68e57fd67e525cb2b",
       "IPY_MODEL_644bffbb621244faa331f8cde91c8f78",
       "IPY_MODEL_5901cc21e51d477d937541d264af3fda"
      ],
      "layout": "IPY_MODEL_4014402ce60647afa00365d41ac12264"
     }
    },
    "644bffbb621244faa331f8cde91c8f78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_799d600da6fe49e48e3909cca4843386",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1b7a1f23f4ed44bda9066b869bdaddf1",
      "value": 3
     }
    },
    "64f365d454be4b55b59c7c1f0b960d17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6797160bcd644bce88dadfc596d153a6",
      "placeholder": "​",
      "style": "IPY_MODEL_812ee2c261764677ae7f1cc278285bab",
      "value": "Login successful"
     }
    },
    "6797160bcd644bce88dadfc596d153a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68577c1cec5f4b00bc99715a3c08df8d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "799d600da6fe49e48e3909cca4843386": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "812ee2c261764677ae7f1cc278285bab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a02d38bfe804a0fb4826cb3e881899b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8f1e5ea19a4d4e6893ddbd3e9fbad481": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9bc6f0a4987940e98b7fe5e94d2c427e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cac50e0e9b2c4046be586067164f0f59",
       "IPY_MODEL_0422f8362a1a4d56a79ecceba8162e73",
       "IPY_MODEL_d48ebe64e8bb4badb0cc9bc64fb492de",
       "IPY_MODEL_64f365d454be4b55b59c7c1f0b960d17"
      ],
      "layout": "IPY_MODEL_fa4745d48e53457b981a8b232805d211"
     }
    },
    "a11250a257d342229e90862f4fdf9fca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a28fc4d884d34294bbe8ace07a95561c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a664acb85354486abad3bb14ab1c41ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "abc4f72e988d4d2f858ae245d519b671": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbff068036124522a42e87cca208a142",
      "placeholder": "​",
      "style": "IPY_MODEL_02706a9956cd4a11add8515d709e41ed",
      "value": " 700/700 [00:00&lt;00:00, 2535.68 examples/s]"
     }
    },
    "ae6cf00577974250a29b6293a973b53f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b485d8b8d19443b49188e2d5ffdf7fff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e29a07d7a144b42ab4cdca49c0b4f6b",
      "placeholder": "​",
      "style": "IPY_MODEL_cfeb971e25864f0b973deea992ed648e",
      "value": "Map: 100%"
     }
    },
    "cac50e0e9b2c4046be586067164f0f59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a11250a257d342229e90862f4fdf9fca",
      "placeholder": "​",
      "style": "IPY_MODEL_501ef8141c6143338a01b86210e057e1",
      "value": "Token is valid (permission: read)."
     }
    },
    "cbd26274a21d40e8b6ef028369e70bcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cfeb971e25864f0b973deea992ed648e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d48ebe64e8bb4badb0cc9bc64fb492de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_53d00ebb4cd14452bdc4d2bfa2cb7c88",
      "placeholder": "​",
      "style": "IPY_MODEL_dbb5068ea6cd4497a0bd2a1a96d4acbc",
      "value": "Your token has been saved to /root/.cache/huggingface/token"
     }
    },
    "dbb5068ea6cd4497a0bd2a1a96d4acbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dbff068036124522a42e87cca208a142": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa4745d48e53457b981a8b232805d211": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
